name: Run Job Scraper (Lovable ingest-jobs)

on:
  workflow_dispatch:
  schedule:
    # daily at 1:10 AM America/Chicago (07:10 UTC in winter)
    - cron: "10 7 * * *"

jobs:
  scraper:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install dependencies
        run: npm install

      # ✅ Create seed file at runtime (NO need to commit seeds/)
      - name: Write seed file from GitHub secret
        shell: bash
        env:
          SEED_JSON: ${{ secrets.SEED_JSON }}
        run: |
          if [ -z "$SEED_JSON" ]; then
            echo "❌ SEED_JSON secret is missing"
            exit 1
          fi
          mkdir -p seeds
          echo "$SEED_JSON" > seeds/greenhouse-batch-001.json
          echo "✅ Seed file created: seeds/greenhouse-batch-001.json"
          echo "✅ Seed file size:"
          wc -c seeds/greenhouse-batch-001.json
          echo "✅ First 2 lines (safe):"
          head -n 2 seeds/greenhouse-batch-001.json

      - name: Run scraper and send to Lovable ingest-jobs
        run: node extractors/scraper_send_to_ingest.js
        env:
          SEED_FILE: seeds/greenhouse-batch-001.json
          INGEST_JOBS_URL: ${{ secrets.INGEST_JOBS_URL }}
          SCRAPER_SECRET_KEY: ${{ secrets.SCRAPER_SECRET_KEY }}
          REQUEST_DELAY_MS: "150"
          MAX_RETRIES: "3"
