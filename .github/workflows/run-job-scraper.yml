name: Run Job Scraper

on:
  workflow_dispatch:
    inputs:
      seed_file:
        description: "Seed file (example: seeds/greenhouse-batch-001.json)"
        required: true
        default: "seeds/greenhouse-batch-001.json"

      request_delay_ms:
        description: "Delay between companies (ms). Lower=faster, higher=safer"
        required: true
        default: "250"

      max_retries:
        description: "Retry count for network/Supabase operations"
        required: true
        default: "3"

      supabase_table:
        description: "Supabase table name"
        required: true
        default: "greenhouse_jobs"

jobs:
  scraper:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "npm"

      - name: Install dependencies
        run: npm ci

      - name: Run scraper
        run: node extractors/scraper.js
        env:
          SEED_FILE: ${{ github.event.inputs.seed_file }}
          REQUEST_DELAY_MS: ${{ github.event.inputs.request_delay_ms }}
          MAX_RETRIES: ${{ github.event.inputs.max_retries }}
          SUPABASE_TABLE: ${{ github.event.inputs.supabase_table }}

          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
