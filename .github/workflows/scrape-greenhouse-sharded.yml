name: Scrape Greenhouse Sharded (Lovable ingest-jobs)

on:
  workflow_dispatch:
    inputs:
      shard_index:
        description: "Shard index to run (0..N-1). Leave empty for auto rotation."
        required: false
        default: ""
      shard_size:
        description: "Companies per shard"
        required: true
        default: "100"

  schedule:
    # Every 15 minutes UTC
    - cron: "*/15 * * * *"

concurrency:
  group: greenhouse-sharded
  cancel-in-progress: false

jobs:
  run-shard:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install dependencies
        run: npm install

      - name: Validate master seed JSON (repo file)
        run: node scripts/validate_json.js seeds/greenhouse-us-master.json

      # ✅ Compute TOTAL_SHARDS from the master list and shard_size
      - name: Compute total shards
        id: totals
        shell: bash
        env:
          SHARD_SIZE: ${{ github.event.inputs.shard_size || '100' }}
        run: |
          COUNT=$(node -e "const a=require('fs').readFileSync('seeds/greenhouse-us-master.json','utf8'); const j=JSON.parse(a); console.log(Array.isArray(j)?j.length:0)")
          if [ "$COUNT" -le 0 ]; then
            echo "❌ Master seed has 0 companies"
            exit 1
          fi

          # totalShards = ceil(COUNT / SHARD_SIZE)
          TOTAL_SHARDS=$(( (COUNT + SHARD_SIZE - 1) / SHARD_SIZE ))

          echo "COMPANY_COUNT=$COUNT" >> $GITHUB_OUTPUT
          echo "TOTAL_SHARDS=$TOTAL_SHARDS" >> $GITHUB_OUTPUT

          echo "✅ Master companies: $COUNT"
          echo "✅ Shard size: $SHARD_SIZE"
          echo "✅ Total shards: $TOTAL_SHARDS"

      # ✅ Compute shard index safely: (minuteOfDay/15) % TOTAL_SHARDS
      - name: Compute shard index (safe auto)
        id: shard
        shell: bash
        env:
          INPUT_SHARD_INDEX: ${{ github.event.inputs.shard_index }}
          TOTAL_SHARDS: ${{ steps.totals.outputs.TOTAL_SHARDS }}
        run: |
          if [ -n "$INPUT_SHARD_INDEX" ]; then
            echo "SHARD_INDEX=$INPUT_SHARD_INDEX" >> $GITHUB_OUTPUT
            echo "✅ Using manual shard index: $INPUT_SHARD_INDEX"
            exit 0
          fi

          H=$(date -u +%H)
          M=$(date -u +%M)
          MINUTES=$((10#$H * 60 + 10#$M))
          BASE=$(( MINUTES / 15 ))

          # Safe modulo so it never goes out of range
          SHARD_INDEX=$(( BASE % TOTAL_SHARDS ))

          echo "SHARD_INDEX=$SHARD_INDEX" >> $GITHUB_OUTPUT
          echo "✅ Auto shard index: $SHARD_INDEX (base=$BASE, minuteOfDay=$MINUTES, totalShards=$TOTAL_SHARDS)"

      - name: Build runtime shard seed file
        id: buildseed
        shell: bash
        env:
          MASTER_SEED_FILE: seeds/greenhouse-us-master.json
          SHARD_INDEX: ${{ steps.shard.outputs.SHARD_INDEX }}
          SHARD_SIZE: ${{ github.event.inputs.shard_size || '100' }}
          OUT_SEED_FILE: seeds/_runtime_shard.json
        run: |
          node scripts/run_shard.js | tee shard_build.log
          SHARD_OUT=$(grep '^SHARD_OUT=' shard_build.log | sed 's/^SHARD_OUT=//')
          echo "SHARD_OUT=$SHARD_OUT" >> $GITHUB_OUTPUT
          echo "✅ Runtime shard seed: $SHARD_OUT"
          echo "✅ Runtime shard company count:"
          node -e "console.log(JSON.parse(require('fs').readFileSync('$SHARD_OUT','utf8')).length)"

      - name: Run scraper for this shard (last 24h)
        run: node extractors/scraper_send_to_ingest.js
        env:
          SEED_FILE: ${{ steps.buildseed.outputs.SHARD_OUT }}
          INGEST_JOBS_URL: ${{ secrets.INGEST_JOBS_URL }}
          SCRAPER_SECRET_KEY: ${{ secrets.SCRAPER_SECRET_KEY }}
          HOURS_BACK: "24"
          REQUEST_DELAY_MS: "150"
          MAX_RETRIES: "3"
