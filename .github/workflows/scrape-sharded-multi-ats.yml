name: Scrape Sharded Multi-ATS (Greenhouse + Lever + Ashby)

on:
  workflow_dispatch:
    inputs:
      shard_size:
        description: "Companies per shard"
        required: true
        default: "100"
      shards_per_run:
        description: "How many shards per run"
        required: true
        default: "2"
      hours_back:
        description: "Freshness window in hours"
        required: true
        default: "24"

  schedule:
    - cron: "*/10 * * * *" # every 10 minutes

concurrency:
  group: multi-ats-sharded
  cancel-in-progress: false

jobs:
  run:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install deps
        run: npm install

      # ✅ REQUIRED: build ATS master seeds EVERY run so files exist
      - name: Build ATS master seeds (from seeds/companies-master.json)
        shell: bash
        run: |
          if [ ! -f "seeds/companies-master.json" ]; then
            echo "❌ Missing seeds/companies-master.json"
            echo "Create it in repo (20k entries) with careers_url or ATS slugs."
            exit 1
          fi
          node scripts/build_seeds_from_master.js
          echo "✅ Seed files created:"
          ls -lah seeds | sed -n '1,200p'
          echo "✅ Counts:"
          node -e "const fs=require('fs'); const f=(p)=>fs.existsSync(p)?JSON.parse(fs.readFileSync(p,'utf8')).length:0; console.log('greenhouse-master',f('seeds/greenhouse-master.json')); console.log('lever-master',f('seeds/lever-master.json')); console.log('ashby-master',f('seeds/ashby-master.json')); console.log('unknown-master',f('seeds/unknown-master.json'));"

      - name: Compute minute-of-day values
        id: t
        shell: bash
        run: |
          H=$(date -u +%H)
          M=$(date -u +%M)
          MINUTES=$((10#$H * 60 + 10#$M))
          RUN_NUMBER=$(( MINUTES / 10 ))
          echo "MINUTES=$MINUTES" >> $GITHUB_OUTPUT
          echo "RUN_NUMBER=$RUN_NUMBER" >> $GITHUB_OUTPUT
          echo "✅ minuteOfDay=$MINUTES runNumber=$RUN_NUMBER"

      # ---------------------------
      # GREENHOUSE SHARDS
      # ---------------------------
      - name: Run Greenhouse shards
        shell: bash
        env:
          INGEST_JOBS_URL: ${{ secrets.INGEST_JOBS_URL }}
          SCRAPER_SECRET_KEY: ${{ secrets.SCRAPER_SECRET_KEY }}
          SHARD_SIZE: ${{ github.event.inputs.shard_size || '100' }}
          SHARDS_PER_RUN: ${{ github.event.inputs.shards_per_run || '2' }}
          RUN_NUMBER: ${{ steps.t.outputs.RUN_NUMBER }}
          HOURS_BACK: ${{ github.event.inputs.hours_back || '24' }}
        run: |
          set -e
          MASTER="seeds/greenhouse-master.json"
          COUNT=$(node -e "const fs=require('fs'); const j=JSON.parse(fs.readFileSync('$MASTER','utf8')); console.log(Array.isArray(j)?j.length:0)")
          if [ "$COUNT" -le 0 ]; then
            echo "⚠️ Greenhouse master empty, skipping"
            exit 0
          fi
          TOTAL=$(( (COUNT + SHARD_SIZE - 1) / SHARD_SIZE ))
          echo "✅ Greenhouse companies=$COUNT totalShards=$TOTAL"

          BASE_SLOT=$(( RUN_NUMBER * SHARDS_PER_RUN ))
          i=0
          while [ $i -lt $SHARDS_PER_RUN ]; do
            IDX=$(( (BASE_SLOT + i) % TOTAL ))
            OUT="seeds/_gh_shard_${IDX}.json"

            MASTER_SEED_FILE="$MASTER" SHARD_INDEX="$IDX" SHARD_SIZE="$SHARD_SIZE" OUT_SEED_FILE="$OUT" node scripts/run_shard.js

            SEED_FILE="$OUT" \
            INGEST_JOBS_URL="$INGEST_JOBS_URL" \
            SCRAPER_SECRET_KEY="$SCRAPER_SECRET_KEY" \
            HOURS_BACK="$HOURS_BACK" \
            REQUEST_DELAY_MS="150" \
            MAX_RETRIES="3" \
            node extractors/scraper_send_to_ingest.js

            i=$((i+1))
          done

      # ---------------------------
      # LEVER SHARDS
      # ---------------------------
      - name: Run Lever shards
        shell: bash
        env:
          INGEST_JOBS_URL: ${{ secrets.INGEST_JOBS_URL }}
          SCRAPER_SECRET_KEY: ${{ secrets.SCRAPER_SECRET_KEY }}
          SHARD_SIZE: ${{ github.event.inputs.shard_size || '100' }}
          SHARDS_PER_RUN: ${{ github.event.inputs.shards_per_run || '2' }}
          RUN_NUMBER: ${{ steps.t.outputs.RUN_NUMBER }}
          HOURS_BACK: ${{ github.event.inputs.hours_back || '24' }}
        run: |
          set -e
          MASTER="seeds/lever-master.json"
          COUNT=$(node -e "const fs=require('fs'); const j=JSON.parse(fs.readFileSync('$MASTER','utf8')); console.log(Array.isArray(j)?j.length:0)")
          if [ "$COUNT" -le 0 ]; then
            echo "⚠️ Lever master empty, skipping"
            exit 0
          fi
          TOTAL=$(( (COUNT + SHARD_SIZE - 1) / SHARD_SIZE ))
          echo "✅ Lever companies=$COUNT totalShards=$TOTAL"

          BASE_SLOT=$(( RUN_NUMBER * SHARDS_PER_RUN ))
          i=0
          while [ $i -lt $SHARDS_PER_RUN ]; do
            IDX=$(( (BASE_SLOT + i) % TOTAL ))
            OUT="seeds/_lever_shard_${IDX}.json"

            MASTER_SEED_FILE="$MASTER" SHARD_INDEX="$IDX" SHARD_SIZE="$SHARD_SIZE" OUT_SEED_FILE="$OUT" node scripts/run_shard.js

            SEED_FILE="$OUT" \
            INGEST_JOBS_URL="$INGEST_JOBS_URL" \
            SCRAPER_SECRET_KEY="$SCRAPER_SECRET_KEY" \
            HOURS_BACK="$HOURS_BACK" \
            REQUEST_DELAY_MS="150" \
            MAX_RETRIES="3" \
            node extractors/scrape_lever_send_to_ingest.js

            i=$((i+1))
          done

      # ---------------------------
      # ASHBY SHARDS
      # ---------------------------
      - name: Run Ashby shards
        shell: bash
        env:
          INGEST_JOBS_URL: ${{ secrets.INGEST_JOBS_URL }}
          SCRAPER_SECRET_KEY: ${{ secrets.SCRAPER_SECRET_KEY }}
          SHARD_SIZE: ${{ github.event.inputs.shard_size || '100' }}
          SHARDS_PER_RUN: ${{ github.event.inputs.shards_per_run || '2' }}
          RUN_NUMBER: ${{ steps.t.outputs.RUN_NUMBER }}
          HOURS_BACK: ${{ github.event.inputs.hours_back || '24' }}
        run: |
          set -e
          MASTER="seeds/ashby-master.json"
          COUNT=$(node -e "const fs=require('fs'); const j=JSON.parse(fs.readFileSync('$MASTER','utf8')); console.log(Array.isArray(j)?j.length:0)")
          if [ "$COUNT" -le 0 ]; then
            echo "⚠️ Ashby master empty, skipping"
            exit 0
          fi
          TOTAL=$(( (COUNT + SHARD_SIZE - 1) / SHARD_SIZE ))
          echo "✅ Ashby companies=$COUNT totalShards=$TOTAL"

          BASE_SLOT=$(( RUN_NUMBER * SHARDS_PER_RUN ))
          i=0
          while [ $i -lt $SHARDS_PER_RUN ]; do
            IDX=$(( (BASE_SLOT + i) % TOTAL ))
            OUT="seeds/_ashby_shard_${IDX}.json"

            MASTER_SEED_FILE="$MASTER" SHARD_INDEX="$IDX" SHARD_SIZE="$SHARD_SIZE" OUT_SEED_FILE="$OUT" node scripts/run_shard.js

            SEED_FILE="$OUT" \
            INGEST_JOBS_URL="$INGEST_JOBS_URL" \
            SCRAPER_SECRET_KEY="$SCRAPER_SECRET_KEY" \
            HOURS_BACK="$HOURS_BACK" \
            REQUEST_DELAY_MS="150" \
            MAX_RETRIES="3" \
            node extractors/scrape_ashby_send_to_ingest.js

            i=$((i+1))
          done
