// extractors/scraper.js
import { getCompanies, ingestJobs } from "../supabase.js";
import { scrapeCompany } from "./router.js";

async function run() {
  console.log("ğŸš€ Starting job scraper...");

  const companies = await getCompanies();
  console.log(`ğŸ“¦ Companies fetched: ${companies.length}`);

  let total = 0;

  for (const company of companies) {
    console.log(`ğŸ” Scraping ${company.name}`);

    try {
      const jobs = await scrapeCompany(company);
      if (!jobs.length) {
        console.warn(`âš ï¸ ${company.name}: 0 jobs`);
        continue;
      }

      await ingestJobs(jobs);
      total += jobs.length;

      console.log(`âœ… ${company.name}: ${jobs.length} jobs`);
    } catch (err) {
      console.error(`âŒ ${company.name} failed:`, err.message);
    }
  }

  console.log(`ğŸ TOTAL jobs scraped: ${total}`);
}

run().catch((err) => {
  console.error("ğŸ’¥ Scraper crashed:", err);
  process.exit(1);
});
