// extractors/scraper.js

import { getCompanies, sendJobs } from "../supabase.js";
import { scrapeCompany } from "./router.js";

console.log("ğŸš€ Starting job scraper...");

async function run() {
  const companies = await getCompanies();

  if (!companies.length) {
    console.warn("âš ï¸ No companies found â€” exiting");
    return;
  }

  console.log(`ğŸ“¦ Companies fetched: ${companies.length}`);

  let totalJobs = 0;

  for (const company of companies) {
    try {
      console.log(`ğŸ” Scraping ${company.name}`);
      const jobs = await scrapeCompany(company);

      if (!jobs.length) {
        console.warn(`âš ï¸ ${company.name}: 0 jobs`);
        continue;
      }

      totalJobs += jobs.length;
      await sendJobs(jobs);
    } catch (err) {
      console.error(`âŒ ${company.name} failed`, err.message);
    }
  }

  console.log(`âœ… TOTAL jobs scraped: ${totalJobs}`);
}

run().catch(err => {
  console.error("âŒ Fatal scraper error", err);
  process.exit(1);
});
