import scrapeGeneric from "./scrapeGeneric.js";
import scrapeAshby from "./ashby.js";
import scrapeGreenhouse from "./greenhouse.js";
import scrapeWorkday from "./workday.js";
import { getCompanies, sendJobs } from "../supabase.js";

console.log("ğŸš€ Starting scraper...");

const SCRAPERS = {
  generic: scrapeGeneric,
  ashby: scrapeAshby,
  greenhouse: scrapeGreenhouse,
  workday: scrapeWorkday
};

async function run() {
  const result = await getCompanies();

  // âœ… FIX: normalize companies to array
  const companies = Array.isArray(result)
    ? result
    : result?.data || [];

  if (!Array.isArray(companies)) {
    throw new Error("âŒ getCompanies() did not return an array");
  }

  if (companies.length === 0) {
    console.warn("âš ï¸ No companies to scrape");
    return;
  }

  let allJobs = [];

  for (const company of companies) {
    console.log(`ğŸ” Scraping ${company.name}`);

    const scraper = SCRAPERS[company.platform] || SCRAPERS.generic;

    try {
      const jobs = await scraper(company);

      if (Array.isArray(jobs) && jobs.length > 0) {
        allJobs.push(...jobs);
        console.log(`âœ… Found ${jobs.length} jobs`);
      } else {
        console.warn(`âš ï¸ Found 0 jobs`);
      }
    } catch (err) {
      console.error(`âŒ Failed scraping ${company.name}`, err.message);
    }
  }

  console.log(`ğŸ“¦ TOTAL jobs scraped: ${allJobs.length}`);

  if (allJobs.length === 0) {
    console.warn("âš ï¸ No jobs to send");
    return;
  }

  await sendJobs(allJobs);

  console.log("ğŸ‰ Scrape completed successfully");
}

run().catch(err => {
  console.error("ğŸ’¥ Scraper crashed:", err);
  process.exit(1);
});
