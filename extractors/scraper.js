import fs from "fs";
import path from "path";
import scrapeGreenhouse from "./greenhouse.js";
import ingestJobs from "./ingestJobs.js";

const SEED_FILE = path.resolve("seeds/greenhouse-us.json");

async function run() {
  console.log("ğŸš€ Starting scraper...");
  console.log("ğŸ“‚ Using seed:", SEED_FILE);

  // ---- Validate seed file ----
  if (!fs.existsSync(SEED_FILE)) {
    throw new Error(`Seed file not found: ${SEED_FILE}`);
  }

  const companies = JSON.parse(fs.readFileSync(SEED_FILE, "utf-8"));

  if (!Array.isArray(companies)) {
    throw new Error("Seed file must be an array of companies");
  }

  console.log(`ğŸ¢ Companies loaded: ${companies.length}`);

  let allJobs = [];

  for (const company of companies) {
    if (
      company.ats !== "greenhouse" ||
      !company.greenhouse_company
    ) {
      continue;
    }

    console.log(`ğŸ” Scraping ${company.name} (greenhouse)`);

    try {
      const jobs = await scrapeGreenhouse(company.greenhouse_company);

      console.log(`âœ… ${company.name}: ${jobs.length} jobs`);

      allJobs.push(
        ...jobs.map(job => ({
          ...job,
          company: company.name,
          ats: "greenhouse"
        }))
      );
    } catch (err) {
      console.warn(`âš ï¸ Greenhouse API failed for ${company.name}`);
    }
  }

  console.log(`ğŸ“¦ Total jobs scraped: ${allJobs.length}`);

  if (allJobs.length === 0) {
    console.log("âš ï¸ No jobs to ingest");
    return;
  }

  console.log(`ğŸ“¤ Sending ${allJobs.length} jobs to Supabase`);
  await ingestJobs(allJobs);

  console.log("âœ… Scraper finished successfully");
}

run().catch(err => {
  console.error("ğŸ’¥ Scraper crashed:", err.message);
  process.exit(1);
});
