import { getCompanies, sendJobs } from "../supabase.js";
import { routeATS } from "./router.js";

const BATCH_SIZE = 200;

(async function runScraper() {
  const companies = await getCompanies();
  console.log(`ğŸ“¦ Companies to scrape: ${companies.length}`);

  let allJobs = [];

  for (const company of companies) {
    console.log(`ğŸ” Scraping ${company.name}`);

    const jobs = await routeATS(company);

    console.log(`â¡ï¸ Found ${jobs.length} jobs`);

    // âš ï¸ DO NOT over-filter
    const normalized = jobs.map(job => ({
      ...job,
      source: "github-scraper",
    }));

    allJobs.push(...normalized);
  }

  console.log(`âœ… TOTAL jobs scraped: ${allJobs.length}`);

  // ğŸš¨ IMPORTANT DEBUG LOG
  console.log(
    `ğŸš€ Jobs before sending: ${allJobs.length}`
  );

  if (allJobs.length === 0) {
    console.warn("âš ï¸ No jobs to send â€” exiting");
    return;
  }

  // âœ… SEND IN BATCHES
  console.log(`ğŸ“¤ Sending jobs in batches of ${BATCH_SIZE}`);

  for (let i = 0; i < allJobs.length; i += BATCH_SIZE) {
    const batch = allJobs.slice(i, i + BATCH_SIZE);

    console.log(
      `ğŸ“¦ Sending batch ${i / BATCH_SIZE + 1} (${batch.length} jobs)`
    );

    await sendJobs(batch);
  }

  console.log("ğŸ‰ ALL JOBS SENT SUCCESSFULLY");
})();
